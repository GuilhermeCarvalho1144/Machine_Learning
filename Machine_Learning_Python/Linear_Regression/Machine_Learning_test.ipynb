{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LINEAR REGRESSION\n",
    "## Linear Regression apllied to a Google stokes avaloble on Quandl\n",
    "\n",
    "The code use the stokes price avalible on quandl and use this data to fit a linear regression model.\n",
    "\n",
    "First we need to define the features, on this case we took as features the Adj. Close, Adj. Volume and we define two other features HIGH_LOW_PERCENT (HL_PCT) and PERCENT_CHANGE (PCT_CHANGE) this features give us some idea abou the volatility of the stokes. This features are not the best ones but this example should be simple.\n",
    "\n",
    "Next we need to slip the data in pieces, the first piece will be our training data on this data we will fit ou linear reegression model (hyphothesis). The second piece will be our test data on thsi data we will see how accuracy is our hypothesis, and the last piece is the data use to forecast. Them we scale the data\n",
    "\n",
    "The library SKLEARN offers all the functions that we need to computate our model \n",
    "\n",
    "To plot our data we need to transformat the index of the dataframe to be a dtype = datetime. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using matplotlib backend: Qt5Agg\n"
     ]
    }
   ],
   "source": [
    "%matplotlib ##PLOT IN A DIFFERENT WINDOW"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "################################### LINEAR REGRESSION ###########################################\n",
    "## GUILHERME CARVALHO PEREIRA\n",
    "## IMPORTING LIBARIES\n",
    "from sklearn.model_selection import cross_val_predict, train_test_split\n",
    "from sklearn import linear_model\n",
    "import sklearn.preprocessing\n",
    "import math,time, quandl\n",
    "from datetime import datetime as dt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import style\n",
    "\n",
    "## DEFINING THE STYLE OF THE PLOTS\n",
    "style.use('ggplot')\n",
    "## GETING THE DATE SET FORM QUANDL\n",
    "quandl.ApiConfig.api_key = 'G9SiyZ49oi4T_KYraTQs'\n",
    "df = quandl.get('WIKI/GOOGL', index_col='Date', parse_dates=True)\n",
    "## PREVIEWING THE DATA\n",
    "#print(df_raw.head())\n",
    "## GETING THE FEATURES MORE MEANINGFUL\n",
    "df = df[['Adj. Open','Adj. High','Adj. Low','Adj. Close','Adj. Volume']]\n",
    "#################################################################################################\n",
    "## DEFINING THE SPECIAL RELATIONSHIP BETWEEN THE FEATURES\n",
    "## HIGH_LOW_PERCENT (HL_PCT) => THIS FEATURE GIVE US THE PERCENT VOLATILITY OF THE STOCKS\n",
    "df['HL_PCT'] = (df['Adj. High'] - df['Adj. Close'])/df['Adj. Close'] *100 \n",
    "## PERCENT_CHANGE (PCT_CHANGE) => THIS FEATURE GIVE US THE DAILY MOVE OF THE STOCKS\n",
    "df['PCT_change'] = (df['Adj. Close'] - df['Adj. Open']) / df['Adj. Open']*100.0\n",
    "## DEFINING THE DATAFRAME WITH THE SPECIAL RELATIONSHIPS\n",
    "df = df[['Adj. Close','HL_PCT','PCT_change','Adj. Volume']]\n",
    "## PREVIEWING THE DATA\n",
    "#print(df.head())\n",
    "## DEFINING THE LABEL... THE 'THING' WE WANT TO PREDICT\n",
    "forecast_col = 'Adj. Close'\n",
    "## FILLING THE NaN DATA ON THE DATASET\n",
    "df.fillna(-99999, inplace=True)\n",
    "## GETING 10% OF THE DATAFRAME AND TRY TO PREDICT\n",
    "pct_data = 0.01  ##GIVE HOW MUCH OF THE DATASET WE ARE TRYING TO PREDICT\n",
    "forecast_out = int(math.ceil(pct_data*len(df)))\n",
    "## ADD THE LABEL TO THE DATAFRAME\n",
    "df['Label'] = df[forecast_col].shift(-forecast_out)  ##JUST THE COLLUMS 10 DAYS ON THE FUTURE\n",
    "## PREVIEWING THE DATA\n",
    "#print(df.head())\n",
    "## DEFINING X AND y FOR OUR HYPOTHESIS\n",
    "X = np.array(df.drop(['Label'], 1))\n",
    "## SCALING OUR FEATURES\n",
    "X = sklearn.preprocessing.scale(X)\n",
    "## DEFINING THE DATA FRO THE FORECAST\n",
    "X_lately = X[-forecast_out:]  ##DATA TO FORECAST\n",
    "X = X[:-forecast_out]\n",
    "## DEVIDING OUR DATA INTO TRAINING AND DATA SET...TESTE SIZE IN %\n",
    "df.dropna(inplace = `True`)\n",
    "y = np.array(df['Label'])\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2)\n",
    "## DEFINING OUR LINEAR REGRESSION HYPOTHESIS\n",
    "hypo = linear_model.LinearRegression()\n",
    "hypo.fit(X_train, y_train)\n",
    "accuracy = hypo.score(X_test, y_test)\n",
    "##print'THIS ALGORITHM PREDICTS THE OUTPUT WITH A ACCURACY OF {}%'.format(accuracy*100)\n",
    "## PREDICTION THE NEXT PRICE OF THE STOCKS\n",
    "y_predict = hypo.predict(X_lately)\n",
    "#################################################################################################\n",
    "## PREPARING THE DATA SET TO BE PLOT\n",
    "df['Forecast'] = np.nan\n",
    "df.index\n",
    "last_date = df.iloc[-1].name\n",
    "last_unix = time.mktime(time.strptime(str(last_date), \"%Y-%m-%d %H:%M:%S\")) # .timestamp()\n",
    "one_day = 86400\n",
    "next_unix = last_unix + one_day\n",
    "\n",
    "for i in y_predict:\n",
    "    next_date = dt.fromtimestamp(next_unix)\n",
    "    next_unix += one_day\n",
    "    df.loc[next_date] = [np.nan for _ in range(len(df.columns)-1)] + [i]\n",
    "##PLOTING THE DATA AND THE PREDICTION\n",
    "df['Adj. Close'].plot()\n",
    "df['Forecast'].plot()\n",
    "plt.legend(loc=4)\n",
    "plt.xlabel('Date')\n",
    "plt.ylabel('Price')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## BUILDING A LINEAR REGRESSION FROM SCRATCH\n",
    "\n",
    "The code we try to build a linear regression model from scratch, we define function to create a total random dataset and than apply thsi random data to a function to compute the best fit line for data (compute m, the slope, and b, the bias). Further we aplicate a squared error the for the linear model, because this should be a simple exemple we didn't need to feedback the error to our best fit line (keep in mind that this should be the normal standard). On he end we plot our data and our linear model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.7679174484052527 1.6256097560975746\n",
      "18338.5138836773 34997.6\n",
      "0.4760065294855276\n"
     ]
    }
   ],
   "source": [
    "########################## LINEAR REGRESSION FUNCTION FROM SCRATCH ###########################\n",
    "from statistics import mean\n",
    "import numpy as np\n",
    "import random \n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import style\n",
    "## DEFINING THE STYLE OF THE PLOTS\n",
    "style.use('ggplot')\n",
    "\n",
    "''' THIS FUNCTION CREATE A SUDO RADOM DATASET \n",
    "    THE FUNCTION TAKES FOUR PARAMETERS:\n",
    "    size -> THE NUMBER OF DATA POINTS TO BE GENERATE\n",
    "    variance -> THE VARIANCE OF THE DATESET\n",
    "    step -> THE INCREMENET OF THE DATASET. BY DEFAULT step=2\n",
    "    correlation ->THE THE DATA POINTS HAVE ANY CORRELATION. BY DEFAULT correlation = False\n",
    "    \n",
    "    THE FUNCTION RETURNS TWO NUMPY ARRAYS, X AND Y, dtype=np.float64\n",
    "'''\n",
    "def create_dateset(size, variance, step=2, correlation=False):\n",
    "    val = 1\n",
    "    y = []\n",
    "    for i in range(size):\n",
    "        y_temp = val+random.randrange(-variance,variance)\n",
    "        y.append(y_temp)\n",
    "        \n",
    "        if correlation and correlation == 'pos':\n",
    "            val+=step\n",
    "            \n",
    "        elif correlation and correlation == 'neg':\n",
    "            val-=step\n",
    "            \n",
    "    X = [i for i in range(size)]\n",
    "    \n",
    "    return np.array(X, dtype = np.float64), np.array(y, dtype = np.float64)\n",
    "\n",
    "''' THIS FUNCTION CALCULATES THE BEST FIT LINE TO A REGRESSION MODEL\n",
    "    THE FUNCTION TAKES TWO PARAMETES:\n",
    "    X -> DATA TO BE FIT AS THE x AXIS : DATA TYPE => numpy.array\n",
    "    y -> DATA TO BE FIT AS THE y AXIS : DATA TYPE => numpy.array\n",
    "    \n",
    "    THE FUNCTION RETURNS TWO FLOAT NUMBERS, m AND b\n",
    "'''\n",
    "def best_fit_line(X,y):\n",
    "    ## COMPUTATING m\n",
    "    m = (((mean(X)*mean(y)) - mean(X*y))/\n",
    "        ((mean(X)**2)-mean(X**2)))\n",
    "    b = mean(y) - m*mean(X)\n",
    "    ## RETURNING THE SLOPE AND INTERCEPT\n",
    "    return m, b\n",
    "\n",
    "\n",
    "''' THIS FUNCTION CALCULATES THE SQUARED ERROR TO A REGRESSION MODEL\n",
    "    THE FUNCTION TAKES TWO PARAMETES:\n",
    "    y -> DATA TO BE FIT AS THE y AXIS : DATA TYPE => numpy.array\n",
    "    regression_model -> DATA PREDICT USING THE best_fit_line function : DATA TYPE => numpy.array\n",
    "    \n",
    "    THE FUNCTION RETURN ONE FLOAT NUMBER\n",
    "'''\n",
    "def squared_error(y,regression_model):\n",
    "    return sum((regression_model - y) * (regression_model - y))\n",
    "\n",
    "''' THIS FUNCTION CALCULATES THE COEFICIENT OF DETERMINATION TO A REGRESSION MODEL\n",
    "    THIS COEFICIENT TELLS US HOW \"GOOD\" IS THE REGRESSION MODEL...GOOD MODEL OR NOT\n",
    "    A GOOD COEFICENT VALUE IS THE CLOSE TO 1 AS POSSIBLE\n",
    "    THE FUNCTION TAKES TWO PARAMETES:\n",
    "    y -> DATA TO BE FIT AS THE y AXIS : DATA TYPE => numpy.array\n",
    "    regression_model -> DATA PREDICT USING THE best_fit_line function : DATA TYPE => numpy.array\n",
    "    \n",
    "    THE FUNCTION RETURN ONE FLOAT NUMBER\n",
    "'''\n",
    "def coef_of_determination(y, regression_model):\n",
    "    y_mean = [mean(y) for y_line in y]\n",
    "    \n",
    "    squared_error_regression = squared_error(y,regression_model)\n",
    "    squared_error_mean = squared_error(y, y_mean)\n",
    "    \n",
    "    #print y, regression_model, y_mean\n",
    "    print squared_error_regression, squared_error_mean\n",
    "    return 1-(squared_error_regression/squared_error_mean)\n",
    "\n",
    "## TESTING DATA\n",
    "\n",
    "X, y = create_dateset(40,40,2,correlation='pos') \n",
    "\n",
    "\n",
    "## CALLING THE FUNCTION\n",
    "\n",
    "[m,b] = best_fit_line(X,y)\n",
    "\n",
    "print m, b\n",
    "\n",
    "## LINE FIT\n",
    "\n",
    "regression_model = [(m*x)+b for x in X]\n",
    "\n",
    "## TESTING HOW GOOD THE LINE FITS THIS DATA\n",
    "\n",
    "r_squared = coef_of_determination(y, regression_model)\n",
    "print r_squared\n",
    "\n",
    "## PLOTING THE DATA\n",
    "plt.scatter(X,y)\n",
    "plt.plot(X,regression_model , label='LINEAR_REGRESSION', color='b')\n",
    "plt.xlabel('X')\n",
    "plt.ylabel('Y')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Attachments",
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
