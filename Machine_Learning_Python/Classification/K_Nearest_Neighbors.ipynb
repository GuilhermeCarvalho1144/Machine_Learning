{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CLASSIFICATION WITH K-NEAREST NEIGHBORS\n",
    "\n",
    "\n",
    "This code use Sklearn library to implement a classification algorithm (K-Nearest Neighbors). The data use is avalible on https://archive.ics.uci.edu/ml/datasets/Breast+Cancer+Wisconsin+%28Original%29, this data contens information about breast cancer, for more information read the data descripition on the link above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "THE ACCURACY OF THE K-NEARREST NEIGHBORGS IS 93.5714285714%\n"
     ]
    }
   ],
   "source": [
    "################################################# CLASSIFICATION #########################################################\n",
    "## GUILHERME CARVALHO PEREIRA\n",
    "## IMPORTING LIBARIES\n",
    "from sklearn.model_selection import cross_val_predict, train_test_split\n",
    "from sklearn import neighbors\n",
    "import sklearn.preprocessing\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "## DEFINING THE DATAFRAME\n",
    "df = pd.read_csv('breast-cancer-wisconsin.data')\n",
    "\n",
    "## PREVIEW \n",
    "#print (df.head())\n",
    "\n",
    "##CLEANING THE DATAFRAME\n",
    "df.replace('?', -99999, inplace=True) ##REPLACE THE MISSING DATA\n",
    "df.drop(['id'], 1, inplace=True) ##REMOVING THE ID COL\n",
    "\n",
    "## PREVIEW\n",
    "#print(df.head())\n",
    "\n",
    "## DEFINING THE FEATURES\n",
    "X = np.array(df.drop(['class'],1))\n",
    "\n",
    "## DEFINING THE LABEL\n",
    "y = np.array(df['class'])\n",
    "\n",
    "## DEFING THE TRAIN AND TEST SET\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n",
    "\n",
    "## CREATING THE K-NEAREST NEIGHBORGS\n",
    "hypo = neighbors.KNeighborsClassifier()\n",
    "hypo.fit(X_train, y_train)\n",
    "\n",
    "## TESTING THE HYPOTHESIS ACCURACY\n",
    "accuracy = hypo.score(X_test, y_test)\n",
    "print 'THE ACCURACY OF THE K-NEARREST NEIGHBORGS IS {}%'.format(accuracy*100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# K-NEAREST NEIGHBORS FROM SCRATCH\n",
    "\n",
    "On this code we build a K-Nearest Neighbors from scratch. The function that implements the classification algorithm just need three parameters:.\n",
    "\n",
    "    -The data we are traning.\n",
    "    -The data point we want to predict\n",
    "    -Number of points that we want to consider for the K_Nearest Neighbors\n",
    "\n",
    "The function has a error mensage for when K is too large, greater than the total of groups. After this assertion we calculate the distances (euclidian distance) for all the points on the training data (80% of the all dataset), them we separeted the K nearest points. Base on the class of this points we classificate our prediction (voting) and than return the result prediction.\n",
    "\n",
    "The accuracy of the code is computed based on the correct predictions divide by the total predictions\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "THE ACCURACY OF THE K-NEARREST NEIGHBORS IS 92.0863309353%\n"
     ]
    }
   ],
   "source": [
    "########################################## K-NEAREST NEIGHBORS FROM SCRATCH #############################################\n",
    "import numpy as np\n",
    "import math\n",
    "import warnings\n",
    "import pandas as pd\n",
    "import random\n",
    "from collections import Counter\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import style\n",
    "\n",
    "## DEFINING THE STYLE\n",
    "style.use('fivethirtyeight')\n",
    "\n",
    "'''\n",
    "## FIRST TEST\n",
    "dataset = {'k':[[1,2],[2,3],[3,1]], 'r':[[6,5],[7,7],[8,6]]}\n",
    "new_features = [5,7]\n",
    "''' \n",
    "\n",
    "''' PREVIEWING THE DATASET\n",
    "## PLOTING THE DATASET\n",
    "[[plt.scatter(ii[0], ii[1], s=100, color=i) for ii in dataset[i]] for i in dataset]\n",
    "'''\n",
    "## SAME FOR LOOP\n",
    "'''for i in dataset:\n",
    "       for ii in dataset[i]:\n",
    "           plt.scatter(ii[0], ii[1], s=100, color=i)\n",
    "'''\n",
    "'''\n",
    "## POLTING THE NEW FEATURE\n",
    "plt.scatter(new_features[0], new_features[1], s=100)\n",
    "'''\n",
    "\n",
    "''' THIS FUNCTION PREDICT THE CLASSIFICATION OF A POINT BASE ON THE OTHER POINTS NEAR IT\n",
    "    THE FUNCTION TAKES THREE PARAMETERS:\n",
    "    data -> THE TRAINING SET...***SHOULD BE A DICTIONEARY\n",
    "    predict -> THE DATA POINT TO PREDICT...***SHOULD BE A DICTIONEARY\n",
    "    k -> THE NUMBER OF NEAR POINTS TO CONSIDER. BY DEFAULT k=3\n",
    "    \n",
    "    THE FUNCTION RETURNS A PREDICTION FOR THE CLASS OF THE NEW POINT\n",
    "'''\n",
    "\n",
    "\n",
    "def k_nearest_neighbors(data, predict, k=3):\n",
    "    if (len(data) >= k):\n",
    "        warnings.warn('**THE K IS SET TO A VALUE LESS THAN TOTAL VOTING GROUP!**')\n",
    "    distance = []\n",
    "    for group in data:\n",
    "        for features in data[group]:\n",
    "            euclid_dist = np.linalg.norm(np.array(features) - np.array(predict))\n",
    "            distance.append([euclid_dist, group])\n",
    "    \n",
    "    votes = [i[1] for i in sorted(distance)[:k]]\n",
    "    vote_result = Counter(votes).most_common(1)[0][0]\n",
    "    return vote_result\n",
    "\n",
    "############################################################################################\n",
    "## DEFINING THE DATAFRAME\n",
    "df = pd.read_csv('breast-cancer-wisconsin.data')\n",
    "\n",
    "## CLEANING THE DATAFRAME\n",
    "df.replace('?', -99999, inplace=True) ##REPLACE THE MISSING DATA\n",
    "df.drop(['id'], 1, inplace=True) ##REMOVING THE ID COL\n",
    "\n",
    "## SHUFFLING THE DATASET\n",
    "full_data = df.astype(float).values.tolist()\n",
    "random.shuffle(full_data)\n",
    "\n",
    "## DEFENING THE TRAIN AND TEST DATASETS\n",
    "test_size = 0.2  ##  20% OF THE FULL DATA\n",
    "train_set = {2:[],4:[]}\n",
    "test_set = {2:[],4:[]}\n",
    "train_data = full_data[:-int(test_size*len(full_data))]\n",
    "test_data = full_data[-int(test_size*len(full_data)):]\n",
    "for i in train_data:  ##  PASSING THE DATA TO THE DIC\n",
    "    train_set[i[-1]].append(i[:-1])\n",
    "for i in test_data:   ##  PASSING THE DATA TO THE DIC\n",
    "    test_set[i[-1]].append(i[:-1])\n",
    "\n",
    "    \n",
    "## CLASSICATIONG THE DATASET\n",
    "correct = 0\n",
    "total = 0\n",
    "for group in test_set:\n",
    "    for data in test_set[group]:\n",
    "        vote = k_nearest_neighbors(train_set, data, k=5)\n",
    "        if group == vote:\n",
    "            correct += 1\n",
    "        total += 1\n",
    "            \n",
    "## PRINTING THE ACCURACY OF THE CODE\n",
    "print 'THE ACCURACY OF THE K-NEARREST NEIGHBORS IS {}%'.format((float(correct)/total)*100)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
